{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3bb1b6-983e-434f-ac09-1f4be4aa3fe4",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6eb81-a2f4-4bb0-a08e-c116c5bf49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Elegir columnas de dataframe condicionalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40e1d3b-e64d-4d4c-9c1f-1b0b042d8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Decompress\n",
    "import zipfile\n",
    "import tarfile \n",
    "import os\n",
    "import sys\n",
    "import errno\n",
    "\n",
    "\n",
    "#### Json to dataframe\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6420132-1151-4a47-8c79-a91251e93659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in /home/kincaid/.local/lib/python3.12/site-packages (15.0.2)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /home/kincaid/.local/lib/python3.12/site-packages (from pyarrow) (1.26.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d2c2c9-c228-4a98-adf4-9f4a135a2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_logger = [];\n",
    "compressed_dir=\"./data/4/\"\n",
    "json_dir=\"./data/4_json/\"\n",
    "parquet_dir=\"./data/4_parquet/\"\n",
    "parquet_trim_dir=\"./data/4_parquet_trim/\"\n",
    "csv_trim_dir=\"./data/4_csv_trim/\"\n",
    "\n",
    "# Pueden agregar todas las columnas que les sean relevantes\n",
    "relevant_cols = [\"extended_tweet.full_text\", \"user.verified\", \"user.followers_count\", \n",
    "                 \"user.friends_count\", \"quote_count\", \"reply_count\", \"retweet_count\", \n",
    "                 \"favorite_count\", \"lang\", \"entities.hashtags\", \"entities.urls\", \"geo.coordinates\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6081685-9cc4-4e90-85fd-f6d7c687ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sure_path_exists(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "make_sure_path_exists(compressed_dir)\n",
    "make_sure_path_exists(json_dir)\n",
    "make_sure_path_exists(parquet_dir)\n",
    "make_sure_path_exists(parquet_trim_dir)\n",
    "make_sure_path_exists(csv_trim_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3a2d4-d577-4623-959c-207e3e92b6c9",
   "metadata": {},
   "source": [
    "Extraer archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e676e7-8329-4f60-98a6-4bd8ba8e154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing twitter-2021.07.2.tar.gz\n",
      "Processing twitter-2021.07.7.tar.gz\n",
      "Processing twitter-2021.07.19.tar.gz\n",
      "Processing twitter-2021.07.8.tar.gz\n",
      "Processing twitter-2021.07.18.tar.gz\n",
      "Processing twitter-2021.07.15.tar.gz\n",
      "Processing twitter-2021.07.4.tar.gz\n",
      "Processing twitter-2021.07.1.tar.gz\n",
      "Processing twitter-2021.07.3.tar.gz\n",
      "Processing twitter-2021.07.10.tar.gz\n",
      "Processing twitter-2021.07.16.tar.gz\n",
      "Processing twitter-2021.07.11.tar.gz\n",
      "Processing twitter-2021.07.12.tar.gz\n",
      "Processing twitter-2021.07.13.tar.gz\n",
      "Processing twitter-2021.07.5.tar.gz\n",
      "Processing twitter-2021.07.9.tar.gz\n",
      "Processing twitter-2021.07.14.tar.gz\n",
      "Processing twitter-2021.07.20.tar.gz\n",
      "Processing twitter-2021.07.22.tar.gz\n",
      "Processing twitter-2021.07.21.tar.gz\n",
      "Processing twitter-2021.07.24.tar.gz\n",
      "Processing twitter-2021.07.23.tar.gz\n",
      "Processing twitter-2021.07.17.tar.gz\n",
      "Processing twitter-2021.07.6.tar.gz\n",
      "Processing twitter-2021.07.28.tar.gz\n",
      "Processing twitter-2021.07.31.tar.gz\n",
      "Processing twitter-2021.07.26.tar.gz\n",
      "Processing twitter-2021.07.29.tar.gz\n",
      "Processing twitter-2021.07.25.tar.gz\n",
      "Processing twitter-2021.07.27.tar.gz\n",
      "Processing twitter-2021.07.30.tar.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in os.listdir(compressed_dir):\n",
    "    print(\"Processing \" + file)\n",
    "    try:\n",
    "        if file.endswith('.zip'):\n",
    "            with zipfile.ZipFile(compressed_dir+file, 'r') as zip_ref:\n",
    "                zip_ref.extractall(json_dir)\n",
    "        elif file.endswith('tar.gz'):\n",
    "            with tarfile.open(compressed_dir+file) as file:\n",
    "                file.extractall(json_dir)\n",
    "        else:\n",
    "            err_logger.append({\"operation\": \"Process compressed\", \"detail\": compressed_dir + file, \"err\":\"Unrecognized file\"})\n",
    "    except Exception as e:\n",
    "        err_template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        err_message = err_template.format(type(e).__name__, e.args)\n",
    "        err_logger.append({\"operation\":\"Extract\", \"detail\": compressed_dir + file, \"err\":err_message})\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c219b04-0fc8-419a-99fc-87ca94d68279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e096f94-9c4e-41d8-a723-76a0b4d670b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = pd.read_json(json_dir+\"twitter-2021.07.10.json\", lines = True, orient='records')\n",
    "#print(t.shape)\n",
    "#list(t)\n",
    "#t.extended_tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f922f7c2-7f85-4fe5-8c64-61b37a067e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing twitter-2021.07.2.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for file in os.listdir(json_dir):\n",
    "    print(\"Processing \" + file)\n",
    "    data = []\n",
    "    \n",
    "    try:\n",
    "        with open(json_dir+file) as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "\n",
    "    except Exception as e: \n",
    "        err_template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        err_message = err_template.format(type(e).__name__, e.args)\n",
    "        err_logger.append({\"operation\":\"Load json\", \"detail\":json_dir + file, \"err\":err_message})\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # Json to dataframe\n",
    "        df = pd.json_normalize(data)\n",
    "        \n",
    "        # Guardar dataframe completo\n",
    "        #df.to_parquet(parquet_dir+file+\".parquet\", engine='auto', compression='snappy')\n",
    "        \n",
    "        # Seleccionar columnas\n",
    "        df_trim = df.loc[:, relevant_cols]\n",
    "        \n",
    "        # Guardar dataframe reducido\n",
    "        df_trim.to_parquet(parquet_trim_dir+file+\".parquet\", engine='auto', compression='snappy')\n",
    "        \n",
    "        # Guardar en csv\n",
    "        #df.to_csv(csv_trim_dir+file+\".csv\", sep=',', encoding='utf-8')\n",
    "    except Exception as e: \n",
    "        err_template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        err_message = err_template.format(type(e).__name__, e.args)\n",
    "        err_logger.append({\"operation\":\"Dataframe & parquet\", \"detail\":json_dir + file, \"err\":err_message})\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a753e7f-479c-489a-81bb-84f0872c32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Alta demanda de RAM, use con precauci√≥n\n",
    "\n",
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in os.listdir(json_dir):\n",
    "    print(\"Processing \" + file)\n",
    "    \n",
    "    try:\n",
    "        with open(json_dir+file) as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "\n",
    "    except Exception as e: \n",
    "        err_template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        err_message = err_template.format(type(e).__name__, e.args)\n",
    "        err_logger.append({\"operation\":\"Load json\", \"detail\":json_dir + file, \"err\":err_message})\n",
    "        continue\n",
    "    \n",
    "try:\n",
    "    # Json to dataframe\n",
    "    df = pd.json_normalize(data)\n",
    "    df.to_parquet(parquet_dir+\"all.parquet\", engine='auto', compression='snappy')\n",
    "    df_trim = df.loc[:, relevant_cols]\n",
    "    df_trim.to_parquet(parquet_trim_dir+\"all.parquet\", engine='auto', compression='snappy')\n",
    "except Exception as e: \n",
    "    err_template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "    err_message = err_template.format(type(e).__name__, e.args)\n",
    "    err_logger.append({\"operation\":\"Dataframe & parquet\", \"detail\":json_dir + \"all.parquet\", \"err\":err_message})\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f75dd02-ed00-4ee7-b7f5-2cabdbc543cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'operation': 'Load json', 'detail': './data/4_json_fail/twitter-2021.07.2.json', 'err': 'An exception of type JSONDecodeError occurred. Arguments:\\n(\"Expecting \\',\\' delimiter: line 2 column 1 (char 2737)\",)'}]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar todos los errores del proceso\n",
    "print(err_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62caa58-0ff4-4175-9b31-926e80dc436d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d50f2992-0445-496e-9b88-0ab224de8566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87280, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar alguno de los parquet generados\n",
    "df2 = pd.read_parquet(parquet_trim_dir+\"twitter-2021.07.10.json.parquet\")\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc5991d7-cba5-4eb7-be08-3073665c0769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extended_tweet.full_text</th>\n",
       "      <th>user.verified</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>user.friends_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>entities.hashtags</th>\n",
       "      <th>entities.urls</th>\n",
       "      <th>geo.coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aunque sea para la foto jejeje...\\n@monitaf_31...</td>\n",
       "      <td>False</td>\n",
       "      <td>459</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>es</td>\n",
       "      <td>[{'indices': [46, 55], 'text': 'relaxday'}, {'...</td>\n",
       "      <td>[{'display_url': 'twitter.com/i/web/status/1‚Ä¶'...</td>\n",
       "      <td>[14.6405587, -90.7745264]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1400</td>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9122</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>es</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12456</td>\n",
       "      <td>2070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>es</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            extended_tweet.full_text  user.verified  \\\n",
       "0  Aunque sea para la foto jejeje...\\n@monitaf_31...          False   \n",
       "1                                               None          False   \n",
       "2                                               None          False   \n",
       "3                                               None          False   \n",
       "4                                               None           True   \n",
       "\n",
       "   user.followers_count  user.friends_count  quote_count  reply_count  \\\n",
       "0                   459                 503            0            0   \n",
       "1                  1400                 368            0            0   \n",
       "2                     5                 274            0            0   \n",
       "3                  9122                  82            0            0   \n",
       "4                 12456                2070            0            0   \n",
       "\n",
       "   retweet_count  favorite_count lang  \\\n",
       "0              0               0   es   \n",
       "1              0               0   en   \n",
       "2              0               0   pt   \n",
       "3              0               0   es   \n",
       "4              0               0   es   \n",
       "\n",
       "                                   entities.hashtags  \\\n",
       "0  [{'indices': [46, 55], 'text': 'relaxday'}, {'...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                       entities.urls  \\\n",
       "0  [{'display_url': 'twitter.com/i/web/status/1‚Ä¶'...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "             geo.coordinates  \n",
       "0  [14.6405587, -90.7745264]  \n",
       "1                       None  \n",
       "2                       None  \n",
       "3                       None  \n",
       "4                       None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a6046f-59fa-4b63-833b-41ac00eeafbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extended_tweet.full_text',\n",
       " 'user.verified',\n",
       " 'user.followers_count',\n",
       " 'user.friends_count',\n",
       " 'quote_count',\n",
       " 'reply_count',\n",
       " 'retweet_count',\n",
       " 'favorite_count',\n",
       " 'lang',\n",
       " 'entities.hashtags',\n",
       " 'entities.urls',\n",
       " 'geo.coordinates']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d1cdf-e3af-4bb5-a115-9c09d2aa2449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
