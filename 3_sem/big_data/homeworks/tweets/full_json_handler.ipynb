{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b01e49c-2941-4af1-bd72-1e8c1adf287a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7102c9-c212-4eea-b328-995dcada7f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'da\"ta/2020/jsons2/twitter-2020.08.27.json',\n",
       " 'line': '14301',\n",
       " 'created_at': 'Thu Aug 27 01:50:30 +0000 2020',\n",
       " 'place_type': 'city',\n",
       " 'full_name': 'Guadalajara, Jalisco'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(r'''{\"file\":\"da\\\"ta/2020/jsons2/twitter-2020.08.27.json\", \"line\":\"14301\", \"created_at\":\"Thu Aug 27 01:50:30 +0000 2020\", \"place_type\":\"city\", \"full_name\":\"Guadalajara, Jalisco\"}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5408e5b3-c52f-408d-a40a-8ced22fc118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_file\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "# NOTA - cada cuantos archivo json agrupar\n",
    "err_logger_1 = []\n",
    "err_logger_2 = []\n",
    "file_no = 0\n",
    "year = \"2020\"\n",
    "write_no = 0\n",
    "data = []\n",
    "\n",
    "\n",
    "with open(\"./data/full_2020.json\") as f:\n",
    "    for line in f:\n",
    "        #print(line)\n",
    "        try:\n",
    "            data.append(json.loads(fr'''{line}'''))\n",
    "        except Exception as e:\n",
    "            err_template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "            err_message = err_template.format(type(e).__name__, e.args)\n",
    "            err_logger_1.append({\"operation\":\"Load json\", \"detail\":\"full_2020\", \"err\":err_message})\n",
    "    #continue\n",
    "\n",
    "\n",
    "try:\n",
    "    write_no = write_no + 1\n",
    "    print(\"gen_file\")\n",
    "    # Json to dataframe\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # Guardar dataframe completo\n",
    "    df.to_parquet(\"./data/full_2020.parquet\", engine='auto', compression='snappy')\n",
    "\n",
    "    # Guardar en csv\n",
    "    #df.to_csv(\"/content/sample_data/testing.csv\", sep=',', encoding='utf-8')\n",
    "\n",
    "    data = []\n",
    "except Exception as e:\n",
    "    err_template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "    err_message = err_template.format(type(e).__name__, e.args)\n",
    "    err_logger_2.append({\"operation\":\"Dataframe & parquet\", \"detail\":\"full_2020\", \"err\":err_message})\n",
    "    #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0933b9e2-ddfb-4a59-8541-216ddd41db04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'operation': 'Load json',\n",
       "  'detail': 'full_2020',\n",
       "  'err': 'An exception of type JSONDecodeError occurred. Arguments:\\n(\"Expecting \\',\\' delimiter: line 1 column 158 (char 157)\",)'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_logger_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea441a81-7d88-4823-8523-0b11cedcf960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_logger_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3810d8-54fa-4821-b8e4-5147bb2d945d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e13e6-349a-4bdc-b777-ed341a6e653f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee5dd99-5bf8-4b4a-9ff4-b12e890f337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5052fb7d-c9db-4630-bd4f-3999b180a6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27621385, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"./data/full_2020.parquet\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336abe7b-f5d5-402a-8550-5802467acafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>created_at</th>\n",
       "      <th>place_type</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/2020/jsons2/twitter-2020.12.17.json</td>\n",
       "      <td>2</td>\n",
       "      <td>Thu Dec 17 00:00:02 +0000 2020</td>\n",
       "      <td>city</td>\n",
       "      <td>Torreón, Coahuila de Zaragoza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/2020/jsons2/twitter-2020.12.17.json</td>\n",
       "      <td>5</td>\n",
       "      <td>Thu Dec 17 00:00:02 +0000 2020</td>\n",
       "      <td>city</td>\n",
       "      <td>Mérida, Yucatán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/2020/jsons2/twitter-2020.12.17.json</td>\n",
       "      <td>7</td>\n",
       "      <td>Wed Dec 16 18:02:41 +0000 2020</td>\n",
       "      <td>city</td>\n",
       "      <td>Alvarado, Veracruz de Ignacio de la Llave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/2020/jsons2/twitter-2020.12.17.json</td>\n",
       "      <td>8</td>\n",
       "      <td>Thu Dec 17 00:00:03 +0000 2020</td>\n",
       "      <td>city</td>\n",
       "      <td>Cuauhtémoc, Distrito Federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/2020/jsons2/twitter-2020.12.17.json</td>\n",
       "      <td>9</td>\n",
       "      <td>Thu Dec 17 00:00:04 +0000 2020</td>\n",
       "      <td>city</td>\n",
       "      <td>Miguel Hidalgo, Distrito Federal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file line  \\\n",
       "0  data/2020/jsons2/twitter-2020.12.17.json    2   \n",
       "1  data/2020/jsons2/twitter-2020.12.17.json    5   \n",
       "2  data/2020/jsons2/twitter-2020.12.17.json    7   \n",
       "3  data/2020/jsons2/twitter-2020.12.17.json    8   \n",
       "4  data/2020/jsons2/twitter-2020.12.17.json    9   \n",
       "\n",
       "                       created_at place_type  \\\n",
       "0  Thu Dec 17 00:00:02 +0000 2020       city   \n",
       "1  Thu Dec 17 00:00:02 +0000 2020       city   \n",
       "2  Wed Dec 16 18:02:41 +0000 2020       city   \n",
       "3  Thu Dec 17 00:00:03 +0000 2020       city   \n",
       "4  Thu Dec 17 00:00:04 +0000 2020       city   \n",
       "\n",
       "                                   full_name  \n",
       "0              Torreón, Coahuila de Zaragoza  \n",
       "1                            Mérida, Yucatán  \n",
       "2  Alvarado, Veracruz de Ignacio de la Llave  \n",
       "3               Cuauhtémoc, Distrito Federal  \n",
       "4           Miguel Hidalgo, Distrito Federal  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0134bd93-c644-4c39-831d-2dcda8d7f2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['city', 'poi', 'neighborhood', 'admin', 'country'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"place_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbb118-99c5-4510-b231-633d775e938b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c1528-3678-41e5-9c76-faebfc325a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82f496a-deae-4318-8434-8f40e7848a3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "JSON parse error: Column(/created_at) was specified twice in row 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/full_2020.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      5\u001b[0m pq\u001b[38;5;241m.\u001b[39mwrite_table(table, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/full_pysp_2020.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pyarrow/_json.pyx:308\u001b[0m, in \u001b[0;36mpyarrow._json.read_json\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: JSON parse error: Column(/created_at) was specified twice in row 2"
     ]
    }
   ],
   "source": [
    "from pyarrow import json\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "table = json.read_json('./data/full_2020.json') \n",
    "pq.write_table(table, './data/full_pysp_2020.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6c6251-e097-4688-9734-73008041c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- file: string (nullable = true)\n",
      " |-- full_name: string (nullable = true)\n",
      " |-- line: string (nullable = true)\n",
      " |-- place_type: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/home/kincaid/Documents/ucags/data_science_master/3_sem/big_data/homeworks/tweets/data/full_pysp_2020.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m json_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mjson(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/full_2020.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, multiLine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,) \n\u001b[1;32m      9\u001b[0m json_df\u001b[38;5;241m.\u001b[39mprintSchema()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mjson_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/full_pysp_2020.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pyspark/sql/readwriter.py:1721\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/home/kincaid/Documents/ucags/data_science_master/3_sem/big_data/homeworks/tweets/data/full_pysp_2020.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"JsonToParquetPysparkExample\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "json_df = spark.read.json(\"./data/full_2020.json\", multiLine=True,) \n",
    "json_df.printSchema()\n",
    "json_df.write.parquet(\"./data/full_pysp_2020.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4059151f-ec4f-4cec-b439-9d847cf05405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
