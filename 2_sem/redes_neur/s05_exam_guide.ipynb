{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eebe8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682b0de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 23:27:14.140243: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-07 23:27:14.251540: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-07 23:27:14.253729: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 23:27:15.491927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Funciones de activación\n",
    "from tensorflow.keras.activations import elu, exponential, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softmax, softplus, softsign, swish, tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0d4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizadores\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d5507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de perdida\n",
    "from tensorflow.keras.losses import binary_crossentropy, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4b4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neurona():\n",
    "    def __init__(self, n_features, func_activ):\n",
    "        self.pesos = np.random.rand(n_features)\n",
    "        self.bias = np.random.rand()\n",
    "        self.func_activ = func_activ\n",
    "    \n",
    "    def CalcEntradaNeta(self, entrada):\n",
    "        return np.dot(entrada, self.pesos) + self.bias\n",
    "    \n",
    "    def Salida(self, entrada):\n",
    "        return self.func_activ(self.CalcEntradaNeta(entrada))\n",
    "    \n",
    "    # FuncPerdida esta más relacionado con el proceso de entrenamiento \n",
    "    # pero lo estamos englobando en la neurona\n",
    "    def FuncPerdida(self, func_perdida):\n",
    "        self.func_perdida = func_perdida\n",
    "    \n",
    "    def CalcError(self, entrada, y_real):\n",
    "        return self.func_perdida([self.Salida(entrada)], y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2f18e",
   "metadata": {},
   "source": [
    "Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ec7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67c5eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2017101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se va a entrenar para reconocer las clases: [4, 7]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Preferí la implementación de random.sample porque me permite generar n valores random sin repetir\n",
    "classes = random.sample(range(y.min(), y.max()), 2)\n",
    "print(f\"Se va a entrenar para reconocer las clases: {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b28058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿El número de ejemplos en x filtrado (360) es igual al de y filtado? True\n",
      "Las clases filtradas son: [4. 7.]\n"
     ]
    }
   ],
   "source": [
    "#filtered_x = np.ndarray(shape=(0, X.shape[1])) Mala práctica según la documentación\n",
    "filtered_x = np.empty(shape=(0, X.shape[1]))\n",
    "filtered_y = np.empty(shape=0)\n",
    "\n",
    "for clas in classes:\n",
    "    mask_class = np.ma.masked_where(y == clas, y)\n",
    "    filtered_x = np.concatenate((filtered_x, X[mask_class.mask]))\n",
    "    filtered_y = np.concatenate((filtered_y, y[mask_class.mask]))\n",
    "\n",
    "#Validando filtro\n",
    "print(f\"¿El número de ejemplos en x filtrado ({filtered_x.shape[0]}) \\\n",
    "es igual al de y filtado? \\\n",
    "{filtered_x.shape[0] == filtered_y.shape[0]}\")\n",
    "print(f\"Las clases filtradas son: {np.unique(filtered_y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0bcc2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El rango de valores por pixel se cambio a 0.0 - 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Normalizamos los datos para tener un rango 0-1 reemplazando 0-16\n",
    "scaler = MinMaxScaler().fit(filtered_x)\n",
    "normalized_x = scaler.transform(filtered_x)\n",
    "print(f\"El rango de valores por pixel se cambio a {normalized_x.min()} - {normalized_x.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5517dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de 4 = 131\n",
      "Cantidad de 7 = 121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Generamos dos datasets (train 70% y test 30%) \n",
    "x_train, x_test, y_train, y_test = train_test_split(normalized_x, filtered_y, test_size=0.30)\n",
    "\n",
    "# Validando distribución de nuestras clases en train\n",
    "for clas in classes:\n",
    "    print(f\"Cantidad de {clas} = {np.count_nonzero(y_train == clas)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7059893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfbbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf9e48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef57ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0cb6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22800/842422510.py:13: RuntimeWarning: divide by zero encountered in log10\n",
      "  return -(target*np.log10(pred)+(1-target)*(np.log10(1-pred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Epoch 0 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 1 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 2 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 3 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 4 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 5 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 6 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 7 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 8 ==========\n",
      "Average loss:  -inf\n",
      "\n",
      "========== Epoch 9 ==========\n",
      "Average loss:  -inf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation Function\n",
    "def sigmoid(w_sum):\n",
    "    return 1/(1+np.exp(-w_sum))\n",
    "\n",
    "# Get Prediction\n",
    "def predict(features, weights, bias):\n",
    "    return sigmoid(np.dot(features, weights) + bias)\n",
    "\n",
    "# Loss Function\n",
    "def cross_entropy(target, pred):\n",
    "    return -(target*np.log10(pred)+(1-target)*(np.log10(1-pred)))\n",
    "\n",
    "# Update Weights\n",
    "def gradient_descent(x, y, weights, bias, learnrate, pred):\n",
    "    new_weights = []\n",
    "    bias += learnrate*(y-pred)\n",
    "\n",
    "    for w,xi in zip(weights,x):\n",
    "        new_weight = w + learnrate*(y-pred)*xi\n",
    "        new_weights.append(new_weight) \n",
    "    return new_weights, bias\n",
    "\n",
    "# Data\n",
    "#features = np.array(([0.1,0.5,0.2],[0.2,0.3,0.1],[0.7,0.4,0.2],[0.1,0.4,0.3]))\n",
    "#targets = np.array([0,1,0,1])\n",
    "features = x_train\n",
    "targets = y_train\n",
    "\n",
    "epochs = 10\n",
    "learnrate = 0.1\n",
    "    \n",
    "errors = []\n",
    "#weights = np.array([0.4, 0.2, 0.6])\n",
    "weights = np.random.rand(x_train.shape[1])\n",
    "bias = 0.5\n",
    "\n",
    "new_weights = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    for x, y in zip(features, targets):\n",
    "        pred = predict(x, weights, bias)\n",
    "        error = cross_entropy(y, pred)\n",
    "        weights, bias = gradient_descent(x, y, weights, bias, learnrate, pred)\n",
    "    \n",
    "    # Printing out the log-loss error on the training set\n",
    "    out = predict(features, weights, bias)\n",
    "    loss = np.mean(cross_entropy(targets, out))\n",
    "    errors.append(loss)\n",
    "    print(\"\\n========== Epoch\", e,\"==========\")\n",
    "    print(\"Average loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3950be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
